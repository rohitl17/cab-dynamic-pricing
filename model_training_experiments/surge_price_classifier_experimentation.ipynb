{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "execution": {
     "iopub.execute_input": "2021-01-12T04:27:41.318434Z",
     "iopub.status.busy": "2021-01-12T04:27:41.317711Z",
     "iopub.status.idle": "2021-01-12T04:27:42.430020Z",
     "shell.execute_reply": "2021-01-12T04:27:42.429233Z"
    },
    "papermill": {
     "duration": 1.138714,
     "end_time": "2021-01-12T04:27:42.430156",
     "exception": false,
     "start_time": "2021-01-12T04:27:41.291442",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-12T04:27:42.484390Z",
     "iopub.status.busy": "2021-01-12T04:27:42.483603Z",
     "iopub.status.idle": "2021-01-12T04:27:44.932745Z",
     "shell.execute_reply": "2021-01-12T04:27:44.933401Z"
    },
    "papermill": {
     "duration": 2.482487,
     "end_time": "2021-01-12T04:27:44.933541",
     "exception": false,
     "start_time": "2021-01-12T04:27:42.451054",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# loading the required datasets\n",
    "cab_df     = pd.read_csv('cab_rides.csv')\n",
    "weather_df = pd.read_csv('weather.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['distance', 'cab_type', 'time_stamp', 'destination', 'source', 'price',\n",
       "       'surge_multiplier', 'id', 'product_id', 'name'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cab_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['temp', 'location', 'clouds', 'pressure', 'rain', 'time_stamp',\n",
       "       'humidity', 'wind'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-12T04:27:46.281942Z",
     "iopub.status.busy": "2021-01-12T04:27:46.281230Z",
     "iopub.status.idle": "2021-01-12T04:27:46.303266Z",
     "shell.execute_reply": "2021-01-12T04:27:46.302729Z"
    },
    "papermill": {
     "duration": 0.485057,
     "end_time": "2021-01-12T04:27:46.303414",
     "exception": false,
     "start_time": "2021-01-12T04:27:45.818357",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Dropping rows where price value is missing\n",
    "cab_df = cab_df.dropna(axis=0).reset_index(drop=True)\n",
    "\n",
    "#replacing missing rain data with 0\n",
    "weather_df = weather_df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting epoch to date-time format in weather_df\n",
    "weather_df['date_time'] = pd.to_datetime(weather_df['time_stamp'], unit='s')\n",
    "weather_df['time_hour'] = pd.to_datetime(weather_df['date_time']).dt.hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a class column with 0 as default value\n",
    "weather_df['rush_hr'] = 0 \n",
    "\n",
    "# marking rush hour (rush_hr) as '1' f\n",
    "weather_df.loc[((weather_df['time_hour'] >= 6) & \n",
    "       (weather_df['time_hour'] < 10)) |\n",
    "       (weather_df['time_hour'] >= 15) & \n",
    "       (weather_df['time_hour'] < 19),\n",
    "       'rush_hr'] = 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#converting date-time from epoch to date-time in cab_df \n",
    "cab_df['date_time'] = pd.to_datetime(cab_df['time_stamp'], unit='ms')\n",
    "cab_df['date_time'] = cab_df['date_time'].dt.floor('s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a class column with 0 as default value\n",
    "weather_df['rush_hr'] = 0 \n",
    "\n",
    "# find all rows that fulfills the rush_hour set to 1\n",
    "weather_df.loc[((weather_df['time_hour'] >= 6) & \n",
    "       (weather_df['time_hour'] < 10)) |\n",
    "       (weather_df['time_hour'] >= 15) & \n",
    "       (weather_df['time_hour'] < 19),\n",
    "       'rush_hr'] = 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to convert the date into 365 day format\n",
    "# this can be used in the future scope to predict rush hours during holidays\n",
    "\n",
    "weather_df['date_day'] = pd.to_datetime(weather_df['date_time']).dt.dayofyear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Appending Boston to the location to get API value for Longitude and Latitude\n",
    "\n",
    "weather_df['location'] = weather_df['location'] + ' Boston'\n",
    "cab_df['destination'] = cab_df['destination'] + ' Boston'\n",
    "cab_df['source'] = cab_df['source']+ ' Boston'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = cab_df.merge(weather_df, how='inner', left_on=['date_time', 'source'], right_on=['date_time', 'location'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making surge_multiplier as a discrete variable.\n",
    "\n",
    "merged_df.loc[merged_df.surge_multiplier == 1, \"surge_mult\"] = 1\n",
    "merged_df.loc[merged_df.surge_multiplier == 1.25, \"surge_mult\"] = 2\n",
    "merged_df.loc[merged_df.surge_multiplier == 1.5, \"surge_mult\"] = 3\n",
    "merged_df.loc[merged_df.surge_multiplier == 1.75, \"surge_mult\"] = 4\n",
    "merged_df.loc[merged_df.surge_multiplier == 2, \"surge_mult\"] = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a dictionary to map the categorical variables\n",
    "\n",
    "predictive_surge_mapping= {1:1, 2: 1.25, 3:1.5, 4:1.75, 5:2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the below dictionary for the lat-long has been obtained using the Google API\n",
    "\n",
    "source_lat={'North End Boston': 42.3647024,'Beacon Hill Boston': 42.3587999,'North Station Boston': 42.3664424,'Boston University Boston': 42.3504997,\n",
    "'South Station Boston':42.3519217,'Fenway Boston':42.3428653,'Theatre District Boston':42.3518662,'West End Boston':42.3643579,\n",
    "'Back Bay Boston':42.3502648,'Northeastern University Boston':42.3398067,'Haymarket Square Boston':42.3600825,\n",
    "'Financial District Boston': 42.3559219}\n",
    "\n",
    "source_long={'North End Boston':-71.0542339 ,'Beacon Hill Boston':-71.0707389 ,'North Station Boston':-71.061974 ,'Boston University Boston':-71.1053991,\n",
    "'South Station Boston':-71.0550703,'Fenway Boston':-71.1002881,'Theatre District Boston':-71.0642623,'West End Boston':-71.0661193,\n",
    "'Back Bay Boston':-71.0809757,'Northeastern University Boston':-71.0891717,'Haymarket Square Boston':-71.0588801,'Financial District Boston':-71.0549768 }\n",
    "\n",
    "merged_df['location_latitude']=merged_df['location'].map(source_lat)\n",
    "merged_df['location_longitude']=merged_df['location'].map(source_long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining x and y variables\n",
    "\n",
    "x = merged_df[['temp','clouds','pressure','rain','humidity','wind',\n",
    "            'rush_hr', 'location_latitude','location_longitude']]\n",
    "\n",
    "y = merged_df[['surge_mult']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using stratified split for the below\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y,\n",
    "                                                    stratify=y, \n",
    "                                                    test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = y_test['surge_mult'].values\n",
    "y_train = y_train['surge_mult'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the model was trained on SVM and decision tree previously\n",
    "#the best results were obtained using Random Forest\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators = 10, class_weight ='balanced')\n",
    "# Train the model on training data\n",
    "rf.fit(x_train, y_train)\n",
    "y_pred = rf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model to disk using pickle python\n",
    "filename = 'surge_classification_rf_model.sav'\n",
    "pickle.dump(rf, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9143179255918827\n"
     ]
    }
   ],
   "source": [
    "loaded_model = pickle.load(open(filename, 'rb'))\n",
    "result = loaded_model.score(x_test, y_test)\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "papermill": {
   "duration": 17.588168,
   "end_time": "2021-01-12T04:27:53.923872",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-01-12T04:27:36.335704",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
